{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tobac example: Tracking deep convection based on VIS from geostationary satellite retrievals\n",
    "\n",
    "This example notebook demonstrates the use of tobac to track isolated deep convective clouds based on radiances within the VIS using channel 2 (red light - 600 nm) of the GOES-16 imaging instrument in 5-min resolution. The study area is loacted within the CONUS extent of the GOES-E for investigating the formation of deep convection over the Carribean, following the [EUREC4A](eurec4a.eu) initiaive. \n",
    "\n",
    "The data used in this example is saved on the cloud of the Amazon Web Services, providing an efficient way of processing satellite data without facing the need of downloading the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import netCDF4\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "from pyproj import Proj, transform\n",
    "from pyproj import transformer\n",
    "#import rioxarray\n",
    "\n",
    "import xarray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from six.moves import urllib\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tobac itself:\n",
    "import tobac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable a few warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, append=True)\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For acessing data from AWS bucket define bucket specifics\n",
    "bucket_name = 'noaa-goes16'\n",
    "product_name = 'ABI-L2-CMIPC'\n",
    "year = 2020\n",
    "day_of_year = 45\n",
    "hour = 14\n",
    "band = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize s3 client. \n",
    "s3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function for generating keys in S3 bucket\n",
    "def get_s3_keys(bucket, s3_client, prefix = ''):\n",
    "    \"\"\"\n",
    "    Generate the keys in an S3 bucket.\n",
    "\n",
    "    :param bucket: Name of the S3 bucket.\n",
    "    :param prefix: Only fetch keys that start with this prefix (optional).\n",
    "    \"\"\"\n",
    "    \n",
    "    kwargs = {'Bucket': bucket}\n",
    "\n",
    "    if isinstance(prefix, str):\n",
    "        kwargs['Prefix'] = prefix\n",
    "\n",
    "    while True:\n",
    "        resp = s3_client.list_objects_v2(**kwargs)\n",
    "        for obj in resp['Contents']:\n",
    "            key = obj['Key']\n",
    "            if key.startswith(prefix):\n",
    "                yield key\n",
    "\n",
    "        try:\n",
    "            kwargs['ContinuationToken'] = resp['NextContinuationToken']\n",
    "        except KeyError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = get_s3_keys(bucket_name,\n",
    "                   s3_client,\n",
    "                   prefix = f'{product_name}/{year}/{day_of_year:03.0f}/{hour:02.0f}/OR_{product_name}-M6C{band:02.0f}'\n",
    "                  )\n",
    "\n",
    "\n",
    "keys = [key for key in keys][0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show file names\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request data via file names from AWS S3 Server and store data in one xarray data set\n",
    "for k in range(len(keys)):\n",
    "    resp = requests.get(f'https://{bucket_name}.s3.amazonaws.com/{keys[k]}')\n",
    "    file_name = keys[k].split('/')[-1].split('.')[0]\n",
    "    nc4_ds = netCDF4.Dataset(file_name, memory = resp.content)\n",
    "    store = xarray.backends.NetCDF4DataStore(nc4_ds)\n",
    "    if k == 0:\n",
    "        DS = xarray.open_dataset(store)    \n",
    "    else:\n",
    "        DS2 = xarray.open_dataset(store)\n",
    "        DS = xarray.combine_nested([DS, DS2], concat_dim=[\"t\"], combine_attrs = \"override\")\n",
    "print(DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GOES-R grid projection details\n",
    "DS.variables[\"goes_imager_projection\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define projection properties for transforming coordinates\n",
    "# Satellite height (perspective_point_height)\n",
    "sat_h = 35786023\n",
    "\n",
    "# Satellite longitude (longitude_of_projection_origin)\n",
    "sat_lon = -75.0\n",
    "\n",
    "# Satellite sweep (sweep_angle_axis)\n",
    "sat_sweep = \"x\"\n",
    "\n",
    "# The projection x and y coordinates equals\n",
    "# the scanning angle (in radians) multiplied by the satellite height (http://proj4.org/projections/geos.html)\n",
    "X = DS.variables['x'][:] * sat_h\n",
    "Y = DS.variables['y'][:] * sat_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform GEOS Projection to Lat-/Lon-Format\n",
    "p = Proj(proj='geos', h=sat_h, lon_0=sat_lon, sweep=sat_sweep)\n",
    "XX, YY = np.meshgrid(X, Y)\n",
    "lons, lats = p(XX, YY, inverse=True)\n",
    "print(len(lons))\n",
    "Sys.exit()\n",
    "lats[np.isnan(DS[\"CMI\"]))] = np.nan\n",
    "print(lats)\n",
    "lons[np.isinf(DS[\"CMI\"])] = np.nan\n",
    "print(np.isnan(X))\n",
    "Sys.exit()\n",
    "DS.coords['x'] = lons\n",
    "DS.coords['y'] = lats\n",
    "print(DS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop to area extent of Tropical Atlantic (Carribean) \n",
    "min_lon = -65.0\n",
    "max_lon = -55.0\n",
    "min_lat = 10.0\n",
    "max_lat = 15.0\n",
    "\n",
    "#DS_subset = band.rio.clip_box(minx=min_lon, miny=min_lat, maxx=max_lon, maxy=max_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up directory to save output and plots:\n",
    "savedir='Save'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "plot_dir=\"Plot\"\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword arguments for the feature detection step\n",
    "parameters_features={}\n",
    "parameters_features['position_threshold']='weighted_diff'\n",
    "parameters_features['sigma_threshold']=0.5\n",
    "parameters_features['min_num']=1\n",
    "parameters_features['target']='maximum'\n",
    "parameters_features['threshold']=0.3\n",
    "parameters_features['dxy']= 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature detection and save results to file:\n",
    "print('starting feature detection')\n",
    "Features=tobac.themes.tobac_v1.feature_detection_multithreshold(DS[\"CMI\"],**parameters_features)\n",
    "Features.to_netcdf(os.path.join(savedir,'Features.nc'))\n",
    "print('feature detection performed and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword arguments for the segmentation step:\n",
    "parameters_segmentation={}\n",
    "parameters_segmentation['target']='maximum'\n",
    "parameters_segmentation['method']='watershed'\n",
    "parameters_segmentation['threshold']=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform segmentation and save results to files:\n",
    "Mask_VIS,Features_VIS=tobac.themes.tobac_v1.segmentation(Features,DS[\"CMI\"],dxy,**parameters_segmentation)\n",
    "print('segmentation VIS performed, start saving results to files')\n",
    "Mask_VIS.to_netcdf(os.path.join(savedir,'Mask_Segmentation_VIS.nc'))              \n",
    "Features_VIS.to_netcdf(os.path.join(savedir,'Features_VIS.nc'))\n",
    "print('segmentation VIS performed and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword arguments for linking step\n",
    "parameters_linking={}\n",
    "parameters_linking['v_max']=20\n",
    "parameters_linking['stubs']=2\n",
    "parameters_linking['order']=1\n",
    "parameters_linking['extrapolate']=1\n",
    "parameters_linking['memory']=0\n",
    "parameters_linking['adaptive_stop']=0.2\n",
    "parameters_linking['adaptive_step']=0.95\n",
    "parameters_linking['subnetwork_size']=100\n",
    "parameters_linking['method_linking']= 'predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform linking and save results to file:\n",
    "Track=tobac.themes.tobac_v1.linking_trackpy(Features,DS[\"CMI\"],dt=dt,dxy=dxy,**parameters_linking)\n",
    "Track.to_netcdf(os.path.join(savedir,'Track.nc'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
